################################################################################
# Project Setup: LLM Optimization and LoRA Fine-Tuning
################################################################################

## 1. Environment Setup

# 1.1 Create and activate the Python virtual environment
python3 -m venv venv
source venv/bin/activate

# 1.2 Install Python dependencies (requires PyTorch, Hugging Face, DSPy, etc.)
pip3 install -r requirements.txt

# 1.3 Install Ollama (Assumes macOS/Linux)
brew install ollama

# 1.4 Download the required LLM model
ollama pull gemma3:4b

################################################################################
## 2. Guesser (DSPy/Ollama) Task
################################################################################

## 2.1 Train the Tfidf Guesser (for RAG Retrieval)
# This step creates the TfidfGuesser.answers.pkl, TfidfGuesser.questions.pkl, 
# TfidfGuesser.tfidf.pkl, and TfidfGuesser.vectorizer.pkl files.
mkdir -p models
python3 guesser.py --guesser_type=Tfidf --question_source=gzjson --questions=../data/qanta.guesstrain.json.gz --logging_file=guesser.log

## 2.2 Run Ollama Server
# This must run in a separate terminal or backgrounded process during step 2.3.
ollama serve

## 2.3 Optimize the Ollama Guesser (DSPy Teleprompting)
# This step optimizes the RAG prompts and saves the result to dspy.json.
# (Note: This will be very slow due to many LLM calls. Be patient!)
python3 ollama_guesser.py

################################################################################
## 3. Buzzer (LoRA/DistilBERT) Task
################################################################################

## 3.1 Run LoRA Fine-Tuning (using Tfidf Guesser for quick test)
# Use a small limit (e.g., 100) for a proof-of-concept run.
# This confirms the LoRA implementation and the correct unfreezing of parameters.
python3 lorabert_buzzer.py \
    --questions=../data/qanta.buzztrain.json.gz \
    --secondary_questions=../data/qanta.buzzdev.json.gz \
    --buzzer_guessers=Tfidf \
    --load=True \
    --buzzer_type='lorabert' \
    --limit=100

## 3.2 Final LoRA Fine-Tuning (using Optimized Ollama Guesser)
# Train the buzzer using the superior, optimized guesses saved in dspy.json.
# This is the version that needs to be submitted.
python3 lorabert_buzzer.py \
    --questions=../data/qanta.buzztrain.json.gz \
    --secondary_questions=../data.qanta.buzzdev.json.gz \
    --buzzer_guessers=Ollama \
    --load=True \
    --buzzer_type='lorabert' \
    --limit=100